{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Over- und Underfitting**\n",
        "\n",
        "Dieses Colab-Notebook zeigt die Auswirkungen von Over- und Underfitting anhand von Testdaten sowie der Funktionswahl.\n",
        "\n",
        "Quelle: https://github.com/WillKoehrsen/Data-Analysis/blob/master/over_vs_under/Over%20vs%20Under%20Fitting%20Example.ipynb"
      ],
      "metadata": {
        "id": "1ujX1OBIq_qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "Wir importieren zuerst die benötigten Libraries"
      ],
      "metadata": {
        "id": "A4M0T_JOreEz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXzPQezxq5d1"
      },
      "outputs": [],
      "source": [
        "# Numpy und Pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scikit-Learn für Machine Learning\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Matplotlib für Plots\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Matplotlib-Parameter\n",
        "matplotlib.rcParams['font.size'] = 12\n",
        "matplotlib.rcParams['figure.titlesize'] = 16\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 7]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funktion definieren\n",
        "\n",
        "Als erstes müssen wir eine Funktion definieren, um welche sich nachher unsere Daten streuen werden. Wir verwenden in unserem Beispiel folgende Funktion:\n",
        "\n",
        "$$y = f(x) = \\sin(1.2 \\cdot x \\cdot \\pi)$$\n",
        "\n",
        "Anschliessend generieren wir einige Testdaten und fügen etwas Rauschen (Streuung dazu)"
      ],
      "metadata": {
        "id": "HxUMrgy_r3wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verteilungs-Initialisierung für die Random-Funktion\n",
        "np.random.seed(42)\n",
        "\n",
        "# Funktion definieren - Diese versucht das Modell anschliessend nachzubilden\n",
        "def true_gen(x):\n",
        "    y = np.sin(1.2 * x * np.pi)\n",
        "    return(y)\n",
        "\n",
        "# x und y Werte generieren. bei den y-Werten werden noch Abweichungen hinzugefügt.\n",
        "x = np.sort(np.random.rand(120))\n",
        "y = true_gen(x) + 0.1 * np.random.randn(len(x))"
      ],
      "metadata": {
        "id": "U69US4Ker-OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainings-Daten generieren**\n",
        "\n",
        "Nun generieren wir zufällige Trainings- und Testdaten. Für ein besseres Verständnis, visualisieren wir anschliessend die Daten."
      ],
      "metadata": {
        "id": "NdzLZzUWt7iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainings-Werte zufällig erstellen\n",
        "random_ind = np.random.choice(list(range(120)), size = 120, replace=False)\n",
        "xt = x[random_ind]\n",
        "yt = y[random_ind]\n",
        "\n",
        "# Training- und Testdaten erstellen\n",
        "train = xt[:int(0.7 * len(x))]\n",
        "test = xt[int(0.7 * len(x)):]\n",
        "\n",
        "y_train = yt[:int(0.7 * len(y))]\n",
        "y_test = yt[int(0.7 * len(y)):]\n",
        "\n",
        "# Die Funktion modellieren\n",
        "x_linspace = np.linspace(0, 1, 1000)\n",
        "y_true = true_gen(x_linspace)"
      ],
      "metadata": {
        "id": "CBIM3I9FuItT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Daten plotten\n",
        "plt.plot(train, y_train, 'ko', label = 'Train');\n",
        "plt.plot(test, y_test, 'ro', label = 'Test')\n",
        "plt.plot(x_linspace, y_true, 'b-', linewidth = 2, label = 'Reale Funktion')\n",
        "plt.legend()\n",
        "plt.xlabel('x'); plt.ylabel('y'); plt.title('Daten');"
      ],
      "metadata": {
        "id": "yjsw9_nbunRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die Grafik zeigt uns anschaulich, dass die generierten Daten sich um unsere reale Sinusfunktion legen (aber doch eine gewisse Zufälligkeit aufweisen)"
      ],
      "metadata": {
        "id": "kaNaES030ihR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynominale Funktion\n",
        "\n",
        "Da wir eine Sinus-Kurve abbilden wollen, müssen wir zwangsläufig auf eine Polynom-Funktion ausweichen (Polynome sind Funktionen n-ten Grades)\n",
        "\n",
        "Wir definieren dazu ein Code-Snippet, welches ein Machine-Learning anhand des mitgegebenen Grades erstellt. Mittels dem Modell können wir anschliessend aufzeigen, wie sich Over- und Underfitting verhält."
      ],
      "metadata": {
        "id": "xgFRDTuA017m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_poly(train, y_train, test, y_test, degrees, plot='train', return_scores=False):\n",
        "\n",
        "    # Create a polynomial transformation of features\n",
        "    features = PolynomialFeatures(degree=degrees, include_bias=False)\n",
        "\n",
        "    # Reshape training features for use in scikit-learn and transform features\n",
        "    train = train.reshape((-1, 1))\n",
        "    train_trans = features.fit_transform(train)\n",
        "\n",
        "    # Create the linear regression model and train\n",
        "    model = LinearRegression()\n",
        "    model.fit(train_trans, y_train)\n",
        "\n",
        "    # Calculate the cross validation score\n",
        "    cross_valid = cross_val_score(model, train_trans, y_train, scoring='neg_mean_squared_error', cv = 5)\n",
        "\n",
        "    # Training predictions and error\n",
        "    train_predictions = model.predict(train_trans)\n",
        "    training_error = mean_squared_error(y_train, train_predictions)\n",
        "\n",
        "    # Format test features\n",
        "    test = test.reshape((-1, 1))\n",
        "    test_trans = features.fit_transform(test)\n",
        "\n",
        "    # Test set predictions and error\n",
        "    test_predictions = model.predict(test_trans)\n",
        "    testing_error = mean_squared_error(y_test, test_predictions)\n",
        "\n",
        "    # Find the model curve and the true curve\n",
        "    x_curve = np.linspace(0, 1, 100)\n",
        "    x_curve = x_curve.reshape((-1, 1))\n",
        "    x_curve_trans = features.fit_transform(x_curve)\n",
        "\n",
        "    # Model curve\n",
        "    model_curve = model.predict(x_curve_trans)\n",
        "\n",
        "    # True curve\n",
        "    y_true_curve = true_gen(x_curve[:, 0])\n",
        "\n",
        "    # Plot observations, true function, and model predicted function\n",
        "    if plot == 'train':\n",
        "        plt.plot(train[:, 0], y_train, 'ko', label = 'Observations')\n",
        "        plt.plot(x_curve[:, 0], y_true_curve, linewidth = 4, label = 'True Function')\n",
        "        plt.plot(x_curve[:, 0], model_curve, linewidth = 4, label = 'Model Function')\n",
        "        plt.xlabel('x'); plt.ylabel('y')\n",
        "        plt.legend()\n",
        "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n",
        "        plt.title('{} Degree Model on Training Data'.format(degrees))\n",
        "        plt.show()\n",
        "\n",
        "    elif plot == 'test':\n",
        "        # Plot the test observations and test predictions\n",
        "        plt.plot(test, y_test, 'o', label = 'Test Observations')\n",
        "        plt.plot(x_curve[:, 0], y_true_curve, 'b-', linewidth = 2, label = 'True Function')\n",
        "        plt.plot(test, test_predictions, 'ro', label = 'Test Predictions')\n",
        "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n",
        "        plt.legend(), plt.xlabel('x'), plt.ylabel('y'); plt.title('{} Degree Model on Testing Data'.format(degrees)), plt.show();\n",
        "\n",
        "    # Return the metrics\n",
        "    if return_scores:\n",
        "        return training_error, testing_error, -np.mean(cross_valid)"
      ],
      "metadata": {
        "id": "6KkLBviR0h4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelle trainieren**"
      ],
      "metadata": {
        "id": "DR4Om1tF6Ggg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynom 1. Grades (Lineare Funktion) -> Underfitting\n",
        "Nun können wir als erstes Beispiel eine Lineare Funktion für das Model verwenden. Da wir eine Sinus-Kurve haben, ist es natürlich nicht möglich, diese Daten real abzubilden. In diesem Fall haben wir es mit Underfitting zu tun."
      ],
      "metadata": {
        "id": "B2utoPEm6KlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 1, plot='train')"
      ],
      "metadata": {
        "id": "nlaWydFz6hhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wenn wir die Prediction ausgeben, sehen wir, wo sich unsere Testdaten befinden werden (kleiner Tipp: Das Model bildet die polynominale Funktion ab)"
      ],
      "metadata": {
        "id": "lzpqdKzj6k17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees = 1, plot='test')"
      ],
      "metadata": {
        "id": "Ixo5vlkp6kPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynom 25. Grades -> Overfitting\n",
        "Im nächsten Beispiel trainieren wir das Model mit einem 25. gradigen Polynom, um das Overfitting (oder auswendiglernen der Daten) zu erzeugen."
      ],
      "metadata": {
        "id": "lBhCJApF6_iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, plot='train', degrees = 25)"
      ],
      "metadata": {
        "id": "iRF4ALHq6-85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir sehen hier bereits in der Model-Funktion, dass das Modell die Daten mehr oder weniger auswendig lernt. Daher wird dieses Modell auch eine hohe Genauigkeit aufweisen."
      ],
      "metadata": {
        "id": "-zlh1HZL7sNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees=25, plot='test')"
      ],
      "metadata": {
        "id": "IekmxBCD73CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynom 5. Grades -> Balanciertes Modell\n",
        "Wir haben nun die zwei extreme gesehen. Das Ziel ist es, ein Modell zu erstellen, welches die Diversität der Daten gut abbilden kann, aber nicht zu extrem den Daten folgt. Im nächsten Versuch werden wir ein Polynom des 5. Grades trainieren, welches einen guten Mittelwert zeigt."
      ],
      "metadata": {
        "id": "00pHQfeV8Aw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, plot='train', degrees = 5)"
      ],
      "metadata": {
        "id": "svIbvOsh8WrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees=5, plot='test')"
      ],
      "metadata": {
        "id": "ahmEeMq88aWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anhand der Testdaten sehen wir, dass das Modell sehr gut der echten Funktion folgt."
      ],
      "metadata": {
        "id": "uGHrwg7q8cRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cross Validation**\n",
        "Wir müssen nun für unser Modell eien Balance finden, damit das Modell nicht over, aber auch nicht underfittet. Hier bietet sich Cross Validation an. Hierbei können wir die Fehlerrate pro Grad des Modells anzeigen. Anhand diesem können wir den optimalen Grad unseres Polynomes bestimmen."
      ],
      "metadata": {
        "id": "FrzFw3UP8hOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grad-Range des Polynomes wählen (in diesem Beispiel: 1 - 40)\n",
        "degrees = [int(x) for x in np.linspace(1, 40, 40)]\n",
        "\n",
        "# DataFrame definieren (für Resultate)\n",
        "results = pd.DataFrame(0, columns = ['train_error', 'test_error', 'cross_valid'], index = degrees)\n",
        "\n",
        "# Für jeden Grad trainieren und testen\n",
        "for degree in degrees:\n",
        "    degree_results = fit_poly(train, y_train, test, y_test, degree, plot=False, return_scores=True)\n",
        "    results.loc[degree, 'train_error'] = degree_results[0]\n",
        "    results.loc[degree, 'test_error'] = degree_results[1]\n",
        "    results.loc[degree, 'cross_valid'] = degree_results[2]"
      ],
      "metadata": {
        "id": "70g47svd9R-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nun können die zehn niedrigsten Cross Validation Fehler ausgegeben werden. Hier sehen wir, dass wir gute Werte mit dem vierten Grad haben"
      ],
      "metadata": {
        "id": "T8CHbXsChjuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('10 Lowest Cross Validation Errors\\n')\n",
        "train_eval = results.sort_values('cross_valid').reset_index(level=0).rename(columns={'index': 'degrees'})\n",
        "train_eval.head(10)"
      ],
      "metadata": {
        "id": "NuOI4WLr9Ydc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wir können die das Verhalten auch grafisch ausgeben, dort sehen wir, wie das Modell sich mit den einzelnen Graden verhält."
      ],
      "metadata": {
        "id": "YxpMl4Zlh2Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results.index, results['cross_valid'], 'go-', ms=6)\n",
        "plt.xlabel('Degrees'); plt.ylabel('Cross Validation Error'); plt.title('Cross Validation Results');\n",
        "plt.ylim(0, 0.2);\n",
        "print('Minimum Cross Validation Error occurs at {} degrees.\\n'.format(int(np.argmin(results['cross_valid'])) + 1))"
      ],
      "metadata": {
        "id": "uXh5V9Da-FXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finales Model**\n",
        "Wir haben vorher gesehen, dass unser Modell bei einem Polynom im 3. Grad am besten performt. Somit können wir die Parameter entsprechend setzen"
      ],
      "metadata": {
        "id": "VFiSp7kY-hBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees=3, plot='train')"
      ],
      "metadata": {
        "id": "jthuKrFR-j56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_poly(train, y_train, test, y_test, degrees=4, plot='test')"
      ],
      "metadata": {
        "id": "DfnggpIB-sOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelle evaluieren**\n",
        "Um die Modelle zu evaluieren, können wir die Training und Testfehlerrate ausgeben und anschliessend miteinander vergleichen"
      ],
      "metadata": {
        "id": "6g3JiU_b-xuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantitativer Vergleich\n",
        "Wir sehen in der nachfolgenden Tabelle, dass die Trainingsfehler kleiner werden, je höher der Grad wird. Das ist ein deutliches Zeichen für Overfitting, da das Modell die Daten auswendig lernt."
      ],
      "metadata": {
        "id": "Bdj63mCV-41g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('10 Lowest Training Errors\\n')\n",
        "train_eval = results.sort_values('train_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n",
        "train_eval.loc[:,['degrees', 'train_error']] .head(10)"
      ],
      "metadata": {
        "id": "O8ZLS_H_-2sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In dieser Tabelle sehen wir, dass der Testfehler beim 5. Grad am niedrigsten ist. Somit haben wir bei diesem Grad einen guten Startpunkt"
      ],
      "metadata": {
        "id": "SIJLmMHEpq7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('10 Lowest Testing Errors\\n')\n",
        "train_eval = results.sort_values('test_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n",
        "train_eval.loc[:,['degrees', 'test_error']] .head(10)"
      ],
      "metadata": {
        "id": "xdGQr-vi_DI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visueller Vergleich\n",
        "Wir können die Werte auch visuell Ausgben, hier sehen wir, dass das Modell beim 5. Grad im Verhältnis zum Training- und Testfehler optimal performt."
      ],
      "metadata": {
        "id": "eZMEdkzD-8Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results.index, results['train_error'], 'b-o', ms=6, label = 'Training Error')\n",
        "plt.plot(results.index, results['test_error'], 'r-*', ms=6, label = 'Testing Error')\n",
        "plt.legend(loc=2); plt.xlabel('Degrees'); plt.ylabel('Mean Squared Error'); plt.title('Training and Testing Curves');\n",
        "plt.ylim(0, 0.05); plt.show()\n",
        "\n",
        "print('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(results['train_error']))))\n",
        "print('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(results['test_error']))))"
      ],
      "metadata": {
        "id": "rRWc70Oh--Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HTgqZ8RSklZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}